import streamlit as st
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score

st.set_page_config(page_title="Smart Layout AI", page_icon="üèóÔ∏è", layout="centered")

st.markdown("""
    <style>
    html, body, [class*="css"]  {
        font-family: 'Segoe UI', sans-serif;
        background-color: #f0f4f8;
    }
    .stButton>button {
        background: linear-gradient(to right, #0f4c75, #3282b8);
        color: white;
        font-size: 18px;
        border-radius: 10px;
        padding: 0.6em 2em;
    }
    div[data-testid="metric-container"] {
        background-color: white;
        border-radius: 12px;
        padding: 1em;
        margin: 10px 0;
        box-shadow: 0px 4px 12px rgba(0,0,0,0.08);
    }
    div[data-testid="metric-container"] > label, div[data-testid="metric-container"] > div {
        color: #1f2937 !important;
        font-weight: 600;
        font-size: 18px;
    }
    </style>
""", unsafe_allow_html=True)

# Specify the sheet name to load
sheet_name = "Sheet1"
df = pd.read_excel("layoutdata.xlsx", sheet_name=sheet_name)
df.columns = df.columns.str.strip()

# Fill NaN values with 0 for width and length columns before calculating average area
for col in ['‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á(‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°)', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß(‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°)', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á(‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î)', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß(‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î)', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á(‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß)', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß(‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß)']:
    df[col] = df[col].fillna(0)

# Calculate average area for each house type
for t in ['‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°', '‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î', '‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß']:
    df[f'‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢({t})'] = df[f'‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á({t})'] * df[f'‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß({t})']

# Target ratios and feature engineering
df['‡∏´‡∏•‡∏±‡∏á‡∏ï‡πà‡∏≠‡∏ã‡∏≠‡∏¢'] = df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'] / df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏≠‡∏¢'].replace(0, 1)
df['%‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß'] = df['‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß'] / df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)
df['%‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î'] = df['‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î'] / df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)
df['%‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°'] = df['‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°'] / df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)
df['%‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢'] = df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢(‡∏ï‡∏£‡∏°)'] / df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)']
df['%‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤'] = df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤(‡∏ï‡∏£‡∏°)'] / df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)']
df['%‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô'] = df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô(5%‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢)'] / df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)']
# Calculate percentage of road in public area, filling NaN with 0 for cases where public area is 0
df['%‡∏ñ‡∏ô‡∏ô‡πÉ‡∏ô‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞'] = (df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô‡∏£‡∏ß‡∏°'] / df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤(‡∏ï‡∏£‡∏°)']).fillna(0)

‡∏ñ‡∏ô‡∏ô_‡∏ï‡πà‡∏≠_‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞_‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ = df['%‡∏ñ‡∏ô‡∏ô‡πÉ‡∏ô‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞'].mean()

# Raw features for the model, including new average area features
X_raw = df[[
    '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)', '‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô',
    '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏ñ‡∏ô‡∏ô', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏ñ‡∏ô‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥', # These were in the user's selected X_raw
    '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢(‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°)', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢(‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î)', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢(‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß)' # New features
]]

# Target ratios for the model
y_ratio = pd.DataFrame({
    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤': df['%‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤'],
    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢': df['%‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢'],
    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô': df['%‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô'], # Corrected to use the newly calculated %‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô
    '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏£‡πà': df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'] / (df['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'] / 1600),
    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°': df['%‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°'],
    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î': df['%‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î'],
    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß': df['%‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß'],
    '‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå': df['‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå'] / df['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)
})

# One-Hot Encode categorical features
X = pd.get_dummies(X_raw, columns=['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô'])

# Split data into training and testing sets for proper model evaluation
X_train, X_test, y_train, y_test = train_test_split(X, y_ratio, test_size=0.2, random_state=42)

# Train the MultiOutputRegressor model
model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42)).fit(X_train, y_train)

# Calculate average '‡∏´‡∏•‡∏±‡∏á‡∏ï‡πà‡∏≠‡∏ã‡∏≠‡∏¢' for each grade
avg_‡∏ã‡∏≠‡∏¢‡∏ï‡πà‡∏≠‡∏´‡∏•‡∏±‡∏á = df.groupby('‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£')['‡∏´‡∏•‡∏±‡∏á‡∏ï‡πà‡∏≠‡∏ã‡∏≠‡∏¢'].mean().to_dict()

# Group data for lookup table
df_group = df[['‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)', '‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°', '‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î', '‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß', '‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á']].copy()
df_group['%‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°'] = df_group['‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°'] / df_group['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)
df_group['%‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î'] = df_group['‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î'] / df_group['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)
df_group['%‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß'] = df_group['‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß'] / df_group['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)
df_group['%‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå'] = df_group['‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå'] / df_group['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏á'].replace(0, 1)

# Define area bins and labels for grouping
bins = [0, 20000, 40000, 60000, 80000, 100000, float("inf")]
labels = ["‚â§20k", "20k-40k", "40k-60k", "60k-80k", "80k-100k", "100k+"]
df_group['‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà'] = pd.cut(df_group['‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)'], bins=bins, labels=labels)

# Calculate mean ratios for house types by grade and area group
grouped_ratio = df_group.groupby(['‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà'], observed=True)[["%‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°", "%‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î", "%‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß", "%‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå"]].mean().round(3)
grouped_ratio_dict = grouped_ratio.to_dict(orient="index")

# Function to adjust house type ratios based on grade-specific policies
def adjust_by_grade_policy(grade, ratios):
    # Existing policy for PRIMO, BELLA, WATTANALAI
    if grade in ['PRIMO', 'BELLA', 'WATTANALAI']:
        ratios[2] = min(ratios[2], 0.2) # Max 20% detached (‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß)
        remain = 1 - ratios[2] - ratios[3] # Recalculate remaining for townhome/semi-detached
        ratios[0] = remain * 0.65 # ‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏° (Index 0)
        ratios[1] = remain * 0.35 # ‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î (Index 1)

    # NEW POLICY: For grades that should only have detached houses (townhome, semi-detached, commercial are 0)
    # Based on data analysis, grades like MONTARA, PRIMAVILLA, and some PARKVILLE instances
    # tend to be exclusively detached. This enforces that policy.
    # 'PARKVILLE' and 'PARK VILLE' are treated as the same grade for this policy.
    if grade in ['MONTARA', 'PRIMAVILLA', 'PARKVILLE', 'PARK VILLE']:
        ratios[0] = 0.0  # Townhome
        ratios[1] = 0.0  # Semi-detached
        ratios[3] = 0.0  # Commercial
        ratios[2] = 1.0  # Detached - set to 100% of remaining plots if other types are 0

    return ratios

# Function to get house type ratios from the lookup table
def get_ratio_from_lookup(grade, area):
    group = labels[-1] # Default to the largest group
    for i, b in enumerate(bins[:-1]):
        if b < area <= bins[i+1]:
            group = labels[i]
            break
    ratio = grouped_ratio_dict.get((grade, group))
    if ratio and any(pd.notna(list(ratio.values()))):
        total = sum([v for v in ratio.values() if pd.notna(v)]) or 1
        ratios = [ratio.get('%‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°', 0)/total,
                  ratio.get('%‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î', 0)/total,
                  ratio.get('%‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß', 0)/total,
                  ratio.get('%‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå', 0)/total]
        return adjust_by_grade_policy(grade, ratios)
    return None

# ====== Streamlit User Interface ======
st.markdown("## üìã ‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£")
with st.form("input_form"):
    col1, col2 = st.columns(2)
    with col1:
        ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î = st.selectbox("üìç ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", sorted(df['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'].dropna().unique()))
        ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á = st.selectbox("üß±Ô∏è ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô", sorted(df['‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô'].dropna().unique()))
    with col2:
        ‡πÄ‡∏Å‡∏£‡∏î = st.selectbox("üèß ‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£", sorted(df['‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£'].dropna().unique()))
        ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà_‡∏ß‡∏≤ = st.number_input("üìÄ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ (‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ß‡∏≤)", min_value=250, value=7500, step=100)
    submitted = st.form_submit_button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå")

# ====== Prediction Logic ======
if submitted:
    area = ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà_‡∏ß‡∏≤ * 4 # Convert square wah to square meters
    rai = area / 1600 # Convert square meters to rai
    input_df = pd.DataFrame([{ '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î': ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î, '‡πÄ‡∏Å‡∏£‡∏î‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£': ‡πÄ‡∏Å‡∏£‡∏î, '‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£(‡∏ï‡∏£‡∏°)': area, '‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô': ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á }])

    # One-Hot Encode input and align columns with training data
    encoded = pd.get_dummies(input_df)
    for col in X.columns:
        if col not in encoded.columns:
            encoded[col] = 0
    encoded = encoded[X.columns] # Ensure column order matches training data

    # Predict using the trained model
    pred = model.predict(encoded)[0]

    # Calculate predicted areas and total houses
    ‡∏û‡∏ó_‡∏™‡∏≤‡∏ò‡∏≤ = pred[0] * area
    ‡∏û‡∏ó_‡∏Ç‡∏≤‡∏¢ = pred[1] * area
    ‡∏û‡∏ó_‡∏™‡∏ß‡∏ô = pred[2] * area
    ‡∏û‡∏ó_‡∏ñ‡∏ô‡∏ô = ‡∏û‡∏ó_‡∏™‡∏≤‡∏ò‡∏≤ * ‡∏ñ‡∏ô‡∏ô_‡∏ï‡πà‡∏≠_‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞_‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ # Use average road ratio from historical data
    ‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏° = pred[3] * rai

    # Determine house type ratios using lookup table or model prediction with policy adjustment
    ratio_hist = get_ratio_from_lookup(‡πÄ‡∏Å‡∏£‡∏î, area)
    if ratio_hist is not None: # Ensure ratio_hist is not None before iterating
        ‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°, ‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î, ‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß, ‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå = [‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏° * r for r in ratio_hist]
    else:
        # If lookup fails, use raw model prediction and apply policy
        total = sum(pred[4:8]) or 1
        raw_ratios = [r / total for r in pred[4:8]]
        raw_ratios = adjust_by_grade_policy(‡πÄ‡∏Å‡∏£‡∏î, raw_ratios)
        ‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°, ‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î, ‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß, ‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå = [‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏° * r for r in raw_ratios]

    # Calculate number of sois (alleys)
    ‡∏ã‡∏≠‡∏¢ = ‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏° / avg_‡∏ã‡∏≠‡∏¢‡∏ï‡πà‡∏≠‡∏´‡∏•‡∏±‡∏á.get(‡πÄ‡∏Å‡∏£‡∏î, 12) # Default to 12 if grade not found

    # ====== Display Prediction Results ======
    st.markdown("---")
    st.markdown("## üåü ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞", f"{‡∏û‡∏ó_‡∏™‡∏≤‡∏ò‡∏≤ / 4:,.0f} ‡∏ï‡∏£.‡∏ß‡∏≤")
        st.metric("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢", f"{‡∏û‡∏ó_‡∏Ç‡∏≤‡∏¢ / 4:,.0f} ‡∏ï‡∏£.‡∏ß‡∏≤")
        st.metric("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏ô", f"{‡∏û‡∏ó_‡∏™‡∏ß‡∏ô / 4:,.0f} ‡∏ï‡∏£.‡∏ß‡∏≤")
        st.metric("‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏ô", f"{‡∏û‡∏ó_‡∏ñ‡∏ô‡∏ô / 4:,.0f} ‡∏ï‡∏£.‡∏ß‡∏≤")
    with col2:
        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏ß‡∏°", f"{‡∏´‡∏•‡∏±‡∏á‡∏£‡∏ß‡∏°:,.0f} ‡∏´‡∏•‡∏±‡∏á")
        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ã‡∏≠‡∏¢", f"{‡∏ã‡∏≠‡∏¢:,.0f} ‡∏ã‡∏≠‡∏¢")

    st.markdown("### üè° ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ö‡πâ‡∏≤‡∏ô")
    st.markdown(f"""
        - ‡∏ó‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏Æ‡∏°: **{‡∏ó‡∏≤‡∏ß‡πÇ‡∏Æ‡∏°:,.0f}** ‡∏´‡∏•‡∏±‡∏á  
        - ‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î: **{‡∏ö‡πâ‡∏≤‡∏ô‡πÅ‡∏ù‡∏î:,.0f}** ‡∏´‡∏•‡∏±‡∏á  
        - ‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß: **{‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß:,.0f}** ‡∏´‡∏•‡∏±‡∏á  
        - ‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå: **{‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå:,.0f}** ‡∏´‡∏•‡∏±‡∏á  
    """)

    # ====== Model Accuracy Display (on Test Set) ======
    # Predict on the test set to evaluate true generalization performance
    y_pred_test = model.predict(X_test)
    mae_test = mean_absolute_error(y_test, y_pred_test)
    r2_test = r2_score(y_test, y_pred_test)

    st.markdown("### üìà ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (Test Set)")
    st.write(f"**MAE (Mean Absolute Error):** {mae_test:.4f}")
    st.write(f"**R¬≤ Score:** {r2_test:.4f}")

st.markdown("---")
st.caption("Developed by mmethaa | Smart Layout AI üöÄ")
